1. 합성곱 신경망을 사용한 컴퓨터 비전  
 대뇌의 시각피질 연구에서 출발하여 1980년대부터 이미지인식 분야에서 사용되었다. 
 일부 복잡한 이미지 처리문제에서 사람을 능가하는 성능을 달성하였다.

  주요 내용으로는 CNN의 구성요소, TF와 케라스를 이용한 CNN의 구현, 가장 뛰어난 성능의 CNN 구조 살펴보기가 있다.
  활용예로는 객체탐지(object detection)와 의미분할(semantic segmentation, 시맨틱 분할이 있다.

2. 시각 피질 구조
합성곱 신경망(CNN)은 대뇌 시각 피질연구에서 시작하였다.
- 데이비드 허블과 토르스텐 비셀, 시각 피질의 구조에 대한 연구(1958)
이 두 연구자는 시각 피질에서 뉴런의 반응 특성을 연구하여 시각 정보 처리에 관한 중요한 기여를 했다.
1959년, Hubel과 Wiesel은 쥐의 시각 피질을 연구하면서 특정한 시각 자극에 반응하는 뉴런의 발견을 시작했다. 
그들은 특히, 두 가지 주요 유형의 시각 피질 뉴런을 발견했다.

- 단순 세포 (Simple Cells)
이 뉴런들은 특정한 위치에서 특정 방향으로 움직이는 가장자리와 같은 단순한 시각 패턴에 반응했다. 
이 뉴런들은 시각적 자극에 대한 특정한 방향 및 위치에 민감하게 반응하는 것으로 나타났다.

- 복잡 세포 (Complex Cells) 
복잡 세포는 단순 세포와 비슷하지만, 특정한 위치에 대한 뉴런의 반응이 덜 정확하게 나타났다. 
그러나 이러한 뉴런들은 특정한 방향으로 움직이는 패턴에 대해 더 일반적으로 반응했다.

이러한 연구 결과는 시각 피질의 계층적 구조와 시각적 계층에서 특정한 패턴에 대한 뉴런의 특성을 처음으로 제시했다. 
이후에는 이러한 연구 결과를 기반으로 컴퓨터 비전 및 합성곱 신경망 (CNN)과 같은 기술의 발전이 이루어지게 되었다. 
CNN은 이러한 시각 피질 연구를 참고하여 이미지 인식 및 패턴 인식과 같은 작업에서 매우 효과적으로 활용되고 있다.

3. 합성곱 층
합성곱 신경망(CNN)에서 합성곱 층(Convolutional Layer)은 가장 중요한 구성 요소 중 하나이다. 
합성곱 층은 주로 이미지 처리와 패턴 인식에 사용되며, 이미지의 지역적 특징을 추출하는 데 탁월하다. 
다음은 합성곱 층의 주요 특징과 동작에 대한 설명이다.

- 합성곱 연산(Convolution Operation) 
합성곱 층은 입력 이미지와 일련의 작은 필터(커널)를 사용하여 합성곱 연산을 수행한다. 
필터는 입력 이미지를 지나가면서 특정한 특징을 감지하고, 이를 통해 새로운 특성 맵을 생성한다. 
이 과정은 이미지의 지역적인 특징을 추출하는 데 도움이 된다.

- 필터(커널) 
필터는 합성곱 연산에 사용되는 작은 행렬로서, 입력 이미지의 작은 영역에 대한 가중치를 나타낸다. 
여러 개의 필터를 사용하면 각각 다른 특징을 추출할 수 있다. 
예를 들어, 하나의 필터는 에지를 감지하고 다른 필터는 텍스처나 색상과 같은 다른 특징을 감지할 수 있다.

- 스트라이드(Stride) 
스트라이드는 필터가 입력 이미지를 이동하는 간격을 나타낸다. 
스트라이드가 크면 출력 크기가 작아지고, 작으면 출력 크기가 커진다. 
적절한 스트라이드를 선택하는 것은 네트워크의 성능에 영향을 미친다.

- 패딩(Padding) 
패딩은 입력 이미지 주변에 추가적인 픽셀을 더하는 것을 말한다. 
패딩을 사용하면 출력 크기를 조절할 수 있으며, 주로 입력 이미지의 가장자리에 위치한 특징을 더 잘 보존할 수 있다.

- 활성화 함수(Activation Function) 
일반적으로 각 합성곱 연산 결과에는 비선형성을 추가하기 위해 활성화 함수가 적용된다. 
주로 ReLU(Rectified Linear Unit)가 사용되며, 음수 값을 0으로 만들어 네트워크의 비선형성을 증가시킨다.

이러한 합성곱 층의 구성 요소들은 이미지에서 다양한 특징을 추출하고, 이를 통해 고수준의 패턴 및 개체를 인식하는 데 기여한다. 
CNN은 이러한 합성곱 층을 여러 겹 쌓아 구성되며, 이를 통해 복잡한 특징과 패턴을 학습할 수 있게 된다.

4. 필터 (합성곱 커널)
필터 또는 커널은 합성곱 신경망(CNN)에서 주로 사용되는 작은 행렬로, 입력 데이터(이미지 또는 다른 종류의 신호)에 적용되어 특정한 패턴이나 특징을 감지하는 데 사용된다. 
이러한 필터는 입력 데이터를 지나가면서 특정한 특징이나 패턴에 대한 정보를 추출하게 된다. 
여러 개의 필터를 사용하여 서로 다른 특징을 동시에 감지할 수 있다.

필터의 역할과 동작 방식

- 특징 추출 
필터는 입력 데이터에 합성곱 연산을 적용하여 특정한 특징을 추출한다. 
필터의 크기는 보통 작지만, 이 작은 크기의 필터를 이동시키면서 전체 입력 이미지를 스캔한다.

- 가중치
각 필터의 요소는 가중치를 나타내며, 이 가중치는 특정한 패턴이나 특징에 대한 감도를 조절한다. 
합성곱 연산은 필터와 입력 데이터의 요소 간에 가중치를 곱하여 합산하는 과정을 포함한다.

- 스트라이드와 패딩 
필터는 일정한 간격으로(스트라이드) 입력 데이터를 스캔하며 합성곱을 수행한다. 
패딩은 입력 데이터 주변에 추가적인 픽셀을 더하는데, 이는 주로 이미지의 가장자리에 위치한 특징을 더 잘 감지하기 위해 사용된다.

- 활성화 함수 
일반적으로 각 합성곱 연산의 결과에는 비선형성을 추가하기 위해 활성화 함수(주로 ReLU)가 적용된다.
이는 네트워크의 더 복잡한 패턴과 특징을 학습할 수 있도록 한다.

예를 들어, 에지 감지를 위한 필터는 수직 에지 또는 수평 에지를 감지하는 데 특화되어 있을 수 있다. 
이 필터를 이미지에 적용하면 해당 방향의 에지에 대한 활성화가 증가하게 된다.
필터는 네트워크의 학습 중에 가중치가 조절되어 다양한 특징을 감지할 수 있게 된다.
따라서 CNN은 여러 개의 필터를 사용하여 입력 데이터의 다양한 특징을 추출하고, 이를 통해 고수준의 패턴 및 개체를 인식하게 된다.

5. 특성맵
특성맵(Feature Map)은 합성곱 신경망(CNN)에서 입력 데이터에 대해 각 필터를 적용하여 얻은 출력값의 집합을 나타낸다. 
각 필터는 입력 데이터의 특정한 특징이나 패턴을 감지하고, 이에 대한 활성화 맵(Activation Map) 또는 특성맵이 생성된다.

특성맵의 생성 과정

- 입력 데이터 
합성곱 층의 입력으로 사용되는 데이터, 주로 이미지 또는 이전 층에서 나온 특성맵이다.

- 필터 적용 
각 필터는 입력 데이터에 대해 합성곱 연산을 수행한다. 
필터는 입력 데이터를 지나가면서 특정한 패턴이나 특징을 감지한다.

- 스트라이드와 패딩 
스트라이드와 패딩을 적용하여 필터가 입력 데이터를 스캔하면서 합성곱을 수행한다. 
스트라이드는 필터가 이동하는 간격을 나타내며, 패딩은 입력 데이터 주변에 추가적인 픽셀을 더한다.

- 활성화 함수 적용 
각 필터의 합성곱 연산 결과에 비선형성을 추가하기 위해 활성화 함수(주로 ReLU)가 적용된다. 
이를 통해 음수 값을 0으로 만들어 비선형성을 도입하고 특성맵을 생성한다.

- 특성맵 생성 
각 필터에 대한 활성화 함수의 결과로서, 필터마다 하나의 특성맵이 생성된다. 
따라서 여러 개의 필터를 사용하면 각각의 필터에 대응하는 여러 개의 특성맵이 생성된다.

특성맵의 역할
특성맵은 입력 데이터에 대한 각 필터의 응답을 시각화한 것으로 볼 수 있다.
각 특성맵은 입력 데이터의 다양한 특징이나 패턴을 나타내며, 여러 개의 특성맵을 통해 입력 데이터의 다양한 특성을 고수준으로 표현할 수 있다. 
이러한 특성맵들은 신경망이 이미지 내의 다양한 개체, 경계, 질감 등을 인식하고 학습하는 데 기여한다.

6. 컬러 채널 (Color Channel)
컬러채널은 이미지에서 색상 정보를 담고 있는 차원을 나타낸다. 
대부분의 디지털 이미지는 빨간색(Red), 초록색(Green), 파란색(Blue) 세 가지 기본 색상 채널로 구성된 RGB (Red-Green-Blue) 컬러 모델을 사용한다. 
이것은 이미지를 표현하는데 사용되는 표준 방식 중 하나이다.

컬러 이미지를 다룰 때, 각각의 픽셀은 세 가지 컬러 채널 값으로 표현된다. 
각 채널은 0에서 255까지의 정수로 표현되며, 이 값은 해당 색상의 강도를 나타낸다. 
예를 들어, (255, 0, 0)은 빨간색 픽셀을 나타내고, (0, 255, 0)은 초록색, (0, 0, 255)는 파란색을 나타낸다.

합성곱 신경망(CNN)은 주로 이미지 처리에 사용되며, 이미지를 대상으로 하는 합성곱 층은 일반적으로 3차원으로 표현된다. 
이 3차원은 가로, 세로, 그리고 채널 차원을 갖는다. 
예를 들어, 100x100 픽셀의 RGB 이미지는 (100, 100, 3)의 형태로 표현된다.

컬러채널을 사용하면 CNN은 이미지의 색상 정보를 고려하여 다양한 시각적 패턴과 특징을 학습할 수 있다. 
이는 흑백 이미지에 비해 훨씬 더 다양한 정보를 활용할 수 있는 장점을 제공한다.

7. 풀링 층
풀링 층(Pooling Layer)은 합성곱 신경망(CNN)에서 사용되는 층 중 하나로, 주로 공간적인 차원을 줄이고 계산량을 감소시키는 역할을 한다. 
풀링 층은 주로 최대 풀링(Max Pooling)과 평균 풀링(Average Pooling)이 두 가지 주요 유형으로 사용된다.

- 최대 풀링(Max Pooling)
각 풀링 영역에서 최대값을 추출하여 새로운 특성 맵을 생성한다.
주로 공간적인 해상도를 감소시키는 데 사용되며, 이미지의 주요 특징을 보존한다.
가장 일반적으로 사용되는 풀링 방법 중 하나이다.

- 평균 풀링(Average Pooling)
각 풀링 영역에서 평균값을 계산하여 새로운 특성 맵을 생성한다.
최대 풀링과 마찬가지로 공간적인 차원을 줄이는 데 사용된다.
최대 풀링보다는 주로 적은 정보를 유지하고 부드러운 특성을 생성하는 데 사용된다.

풀링 층의 특징 및 역할

- 공간적인 차원 감소 
풀링 층은 입력 데이터의 공간적인 차원을 감소시켜 연산량을 줄이고 계산 효율성을 향상시킨다.

- Translation Invariance(이동 불변성) 
풀링 층은 입력에 대해 작은 이동에 대해 불변성을 제공한다. 
즉, 입력 데이터가 약간 이동하더라도 풀링 층의 출력이 크게 변경되지 않는다.

- 학습 가능한 매개변수 없음 
풀링 층은 학습 가능한 가중치나 매개변수가 없다. 
최대값이나 평균을 계산하는 고정된 연산을 수행한다.

- 과적합 방지 
풀링은 주로 불필요한 세부 정보를 제거하고 중요한 특징을 강조하는 데 사용되므로, 과적합(overfitting)을 방지하는 데 일부 기여를 할 수 있다.

풀링 층은 일반적으로 합성곱 층 다음에 위치하여 공간적인 차원을 줄이고 중요한 특징을 추출한 후, 이를 통해 더 깊은 합성곱 층으로 전달된다.

8. CNN 구조
전형적인 합성곱 신경망(CNN) 구조는 주로 합성곱 층(Convolutional Layer), 풀링 층(Pooling Layer), 완전 연결 층(Fully Connected Layer)으로 구성되는데, 
각 층은 입력 데이터를 변환하여 추상화된 특성을 학습한다. 
일반적으로는 다음과 같은 구조를 갖는다.

- 입력 층(Input Layer)
이미지나 다른 형태의 입력 데이터를 받아들인다.
일반적으로 이미지의 경우 RGB 컬러 채널이 있으므로 입력 데이터는 (높이, 너비, 채널) 형태의 3D 텐서로 표현된다.

- 합성곱 층(Convolutional Layer)
이미지의 지역적인 패턴을 감지하고 추출하는 데 사용된다.
여러 개의 필터로 구성되며, 각 필터는 특정한 특성이나 패턴을 감지한다.
활성화 함수(주로 ReLU)를 포함하고, 스트라이드와 패딩을 조절하여 출력 특성맵의 크기를 조절할 수 있다.

- 풀링 층(Pooling Layer)
공간적인 차원을 줄이고 계산량을 감소시키는 데 사용된다.
주로 최대 풀링 또는 평균 풀링을 사용하여 각 영역에서 최대값 또는 평균값을 추출한다.

- 합성곱 층 및 풀링 층의 반복
합성곱 층과 풀링 층을 번갈아가면서 여러 층을 쌓는다.
이러한 다층 구조는 입력 데이터의 다양한 특성을 추출하고 학습한다.

- 완전 연결 층(Fully Connected Layer)
추출된 특성을 이용하여 최종 예측을 수행한다.
주로 분류 문제의 경우 마지막에 소프트맥스 활성화 함수를 사용하여 클래스 확률을 출력한다.

- 출력 층(Output Layer)
분류 문제인 경우 소프트맥스 활성화 함수를 사용하여 각 클래스에 대한 확률을 계산하고, 
회귀 문제인 경우 활성화 함수를 사용하지 않고 직접 출력한다.

이러한 구조는 합성곱과 풀링을 통해 이미지의 지역적인 특성을 계층적으로 추출하고, 
완전 연결 층을 통해 추출된 특성을 기반으로 최종 예측을 수행한다. 
이러한 구조는 이미지 분류, 객체 감지, 세분화 등 다양한 컴퓨터 비전 작업에서 효과적으로 사용된다.

9. LeNet-5 
LeNet-5는 합성곱 신경망(CNN) 중 하나로, 1998년에 Yann LeCun과 그의 동료들에 의해 개발된 초기의 전형적인 CNN 구조 중 하나이다. 
LeNet-5는 주로 손글씨 숫자를 인식하는 데 사용되었으며, 이는 필기체 숫자를 자동으로 읽는데 활용되었다. 
LeNet-5의 주요 특징은 다음과 같다.

- 층 구조
LeNet-5는 합성곱 층, 풀링 층, 완전 연결 층 등의 다층 구조를 가지고 있다.
입력 이미지는 32x32 크기이며, 총 7개의 층으로 구성되어 있다.

- 합성곱 층과 풀링 층
합성곱 층과 풀링 층이 번갈아가며 나타난다.
초기의 LeNet-5에서는 시그모이드 활성화 함수를 사용하며, 
최근의 CNN에서 많이 사용되는 ReLU 활성화 함수보다 덜 일반적인 활성화 함수를 사용했다.

- Subsampling 층
풀링 층을 Subsampling 층으로 표현하기도 한다. 
Subsampling 층은 풀링 층과 유사한 역할을 수행하지만, 가중치가 공유되는 특징이 있다.

- 완전 연결 층
추출된 특성을 기반으로 최종적인 분류를 수행하기 위해 완전 연결 층을 사용한다.
최종 출력은 소프트맥스 활성화 함수를 통해 클래스 확률로 변환된다.

- 작은 필터 크기
LeNet-5에서는 작은 필터 크기를 사용하였는데, 이는 계산 효율성을 높이고 모델 파라미터 수를 줄이는 데 기여했다.

- 서브샘플링(Subsampling)
특성 맵의 크기를 줄이기 위해 서브샘플링을 사용했다. 
이는 픽셀을 버리거나 평균 값을 취하여 공간적 차원을 감소시킨다.

LeNet-5는 CNN의 초창기 구조로서 기본 아이디어를 제시하고, 이후에 발전된 여러 CNN 구조의 기반이 되었다. 
최근의 딥러닝 모델들은 더 깊고 복잡한 구조를 가지고 있지만, 
LeNet-5는 CNN의 발전과 역사적인 중요성을 나타내는 모델 중 하나로 여겨진다.

10. AlexNet  
AlexNet은 2012년에 제롬 후튼(Jeffrey Hinton)과 그의 팀이 개발한 딥러닝 모델로, 
ImageNet Large Scale Visual Recognition Challenge에서 우승한 모델 중 하나이다. 
이 모델은 기존의 컴퓨터 비전 모델들을 뛰어넘는 성능을 보이며, 딥러닝의 주목을 받게 된 중요한 모델 중 하나이다.

주요 특징 및 아키텍처
- 깊은 아키텍처
AlexNet은 당시에는 깊은 신경망으로써 8개의 합성곱-풀링 층과 3개의 완전 연결 층으로 구성되었다.
이 깊이는 당시에는 비상식적으로 깊은 모델로 간주되었으며, 딥러닝의 성능을 향상시키는 데 기여했다.

- ReLU 활성화 함수
AlexNet에서는 시그모이드 함수 대신 ReLU(Rectified Linear Unit) 활성화 함수를 사용했다. 
이는 모델의 비선형성을 증가시켜 학습 능력을 향상시켰다.

- 드롭아웃(Dropout)
AlexNet에서는 과적합을 줄이기 위해 드롭아웃을 처음으로 적용한 모델 중 하나이다. 
드롭아웃은 학습 중에 무작위로 일부 뉴런을 비활성화하여 모델의 일반화 성능을 향상시킨다.

- 합성곱 층과 풀링 층의 조합
다양한 크기의 커널과 다양한 스트라이드를 사용하는 합성곱 층과 최대 풀링 층을 조합하여 공간적인 계층 구조를 형성했다.

- Local Response Normalization (LRN)
LRN은 국소적 정규화를 수행하여 인접한 픽셀 간의 경쟁을 조절했디. 
그러나 이후에는 배치 정규화(Batch Normalization)가 등장하면서 더 효과적인 정규화 방법으로 대체되었다.

- 마지막 완전 연결 층의 대규모 파라미터
AlexNet의 마지막 완전 연결 층은 4096개의 뉴런을 가지고 있었는데, 이는 당시까지의 모델들에 비해 매우 큰 크기였다.
AlexNet은 딥러닝의 성공을 이끈 중요한 모델 중 하나로서, 
더 깊고 복잡한 신경망 구조의 개발과 이미지 분류, 객체 검출, 세분화 등 다양한 컴퓨터 비전 작업에서 영감을 주었다.


11. GoogLeNet
GoogLeNet은 2014년에 Google이 개발한 심층 신경망 모델로, Inception이라는 개념을 토대로 만들어졌다. 
GoogLeNet은 ImageNet Large Scale Visual Recognition Challenge에서 우승한 모델 중 하나이며, 그 전까지의 대부분의 모델과는 다른 특이한 구조를 가지고 있다.

주요 특징 및 아키텍처

- Inception 구조
GoogLeNet은 Inception이라는 구조를 사용하여 네트워크를 설계했다. 
Inception은 서로 다른 크기의 필터(커널)를 동시에 사용하여 다양한 크기의 특징을 추출하고 합치는 아이디어이다.
Inception 모듈은 1x1, 3x3, 5x5 크기의 필터를 동시에 적용하고, 그 결과를 합친다.

-Global Average Pooling
일반적으로 CNN의 Fully Connected Layer는 많은 파라미터를 가지기 때문에 과적합의 위험이 있다.
GoogLeNet에서는 전역 평균 풀링(Global Average Pooling)을 사용하여 특성 맵의 각 채널에 대한 평균을 구하고, 
이를 입력으로 사용하여 Fully Connected Layer를 대체했다.

- Auxiliary Classifiers
GoogLeNet은 중간에 추가된 보조 분류기(Auxiliary Classifier)를 사용하여 그래디언트 소실을 방지하고, 
네트워크의 학습을 돕는 역할을 했다. 
이는 훈련 중에 중간에 손실을 계산하여 네트워크에 추가적인 그래디언트 신호를 제공한다.

- Batch Normalization
GoogLeNet은 Batch Normalization을 사용하여 각 층의 입력을 정규화하여 학습을 안정화시켰다.

- 1x1 Convolution의 활용
1x1 컨볼루션 연산은 다양한 채널 간의 조합을 가능하게 하며, 모델의 복잡성을 낮추고 연산량을 줄이는 데 기여했다.
GoogLeNet은 이전의 모델에 비해 더 깊은 네트워크를 사용하면서도 효율적으로 학습하고 계산량을 줄인 것이 특징이다.
이러한 특징은 네트워크의 성능 향상과 효율성 측면에서 기여하였다. 
GoogLeNet은 딥러닝에서의 효율적인 네트워크 설계에 대한 중요한 기여를 한 모델로 평가된다.

12. VGGNet
VGGNet은 2014년에 나온 딥러닝 모델로, 옥스포드 대학의 Visual Geometry Group (VGG)에서 개발했다. 
VGGNet은 ImageNet Large Scale Visual Recognition Challenge에서 우승한 모델 중 하나로, 간결하면서도 효과적인 구조로 알려져 있다.

주요 특징 및 아키텍처

- 깊은 네트워크 구조
VGGNet은 당시에는 깊은 신경망으로 간주되었는데, 16층(VGG16) 또는 19층(VGG19)의 깊이를 갖고 있다.
작은 필터 크기 3x3을 사용하여 네트워크를 깊게 만들었으며, 
이는 큰 필터 하나를 사용하는 것보다 더 많은 비선형성을 가져오고 파라미터 수를 줄이는 데 도움이 된다.

- 동일한 크기의 필터 사용
VGGNet은 모든 합성곱(Convolutional) 층에서 3x3 크기의 작은 필터를 사용했다. 
이는 여러 층에서 작은 필터를 사용하여 복잡한 패턴을 감지하도록 했으며, 
네트워크 구조를 균일하게 만들어 구현과 이해를 용이하게 했다.

- 풀링 층과 완전 연결 층
합성곱 층 다음에는 최대 풀링(Max Pooling) 층이 따르며, 이어서 완전 연결 층이 나온다.
VGGNet은 마지막에 세 개의 완전 연결 층을 사용하였고, 최종 출력은 소프트맥스 활성화 함수를 사용하여 클래스 확률로 변환된다.

- 많은 파라미터
VGGNet은 많은 수의 파라미터를 갖고 있어, 대량의 데이터와 높은 컴퓨팅 리소스를 필요로 한다. 
이는 네트워크의 복잡성을 증가시키고, 훈련에는 많은 데이터가 필요하다는 한계를 갖게 된다.

VGGNet은 단순하면서도 효과적인 구조로 이미지넷과 같은 대규모 데이터셋에서 높은 성능을 보였다. 
그러나 더 깊고 효과적인 구조들이 등장하면서 현재는 더 최신의 모델들이 VGGNet을 대체하고 있다.

13. ResNet(Residual Network)  
ResNet(Residual Network)은 2015년에 Microsoft Research에서 개발된 딥러닝 신경망 아키텍처로, 
이미지넷 대회에서 우승한 모델 중 하나이다. 
ResNet은 네트워크 깊이의 증가로 인한 그래디언트 소실 문제를 해결하고, 
매우 깊은 네트워크를 학습할 수 있도록 하는 핵심 아이디어를 도입했다.

주요 특징 및 아키텍처
- Residual Block
ResNet의 핵심은 잔여 학습(Residual Learning)이라 불리는 Residual Block입니다.
일반적인 합성곱 층의 출력에 입력을 더해주는 잔여 매핑(residual mapping)을 수행한다. 
수학적으로는 F(x)+x 의 형태로 나타낼 수 있다.
이를 통해 입력 신호를 직접적으로 전달하고 그래디언트 소실 문제를 해결하며, 
깊은 네트워크에서도 효과적으로 학습할 수 있게 되었다.

- 깊은 네트워크 구조
ResNet은 수십, 수백 개의 층으로 이루어진 매우 깊은 네트워크를 가지고 있다.
더 깊은 네트워크를 구성할 때, 잔여 학습의 도입으로 인해 높은 성능을 유지하면서도 그래디언트 소실 문제를 해결할 수 있게 되었다.

- Global Average Pooling (GAP)
ResNet에서는 Fully Connected Layer 대신 Global Average Pooling을 사용한다. 
이는 공간적인 차원을 감소시키면서 파라미터 수를 크게 줄여 과적합을 방지하고 추상화된 특성을 추출하는 데 도움을 준다.

- Skip Connection 및 Bottleneck 구조
ResNet은 Residual Block 내에서 Skip Connection을 도입하여 더욱 효과적으로 정보를 전달한다.
Bottleneck 구조를 사용하여 층의 수를 늘리면서도 계산량을 효율적으로 관리한다.

- 사전 학습된 모델
ResNet은 대규모 이미지 데이터셋에서 미리 훈련된 모델을 사용하여 전이 학습(Transfer Learning)에도 매우 효과적으로 사용된다.
ResNet은 깊은 네트워크에서도 성능이 향상되는 잔여 학습의 개념을 도입하여, 
딥러닝에서 깊은 네트워크의 훈련과 최적화에 있어서 혁신적인 모델 중 하나로 평가된다.

14. Xception 
Xception(Extreme Inception)은 2017년에 François Chollet이 제안한 딥러닝 아키텍처로, 
케라스(Keras)의 창시자 중 한 명인 Chollet이 개발한 것이다. 
Xception은 컨볼루션 연산에서 극단적인 아이디어를 도입하여 Inception 모델의 발전된 형태로 알려져 있다.

주요 특징 및 아키텍처
- Separable Convolution
Xception은 Inception 모델에서 사용되는 컨볼루션 연산을 개선하기 위해 Separable Convolution을 도입했다.
일반적인 컨볼루션은 입력 데이터의 모든 채널 간에 필터를 공유하는 반면, 
Separable Convolution은 각 채널별로 따로따로 공간적 필터와 채널 간 필터를 적용한다.
이로써 파라미터 수를 획기적으로 감소시키고 계산량을 줄일 수 있게 되었다.

- Depthwise Separable Convolution
Separable Convolution을 개량한 Depthwise Separable Convolution은 Separable Convolution을 확장한 것으로,
공간적 필터와 채널 간 필터를 따로따로 적용하는 것에 더해, 
각 채널마다 공간적 필터를 적용한 후에 채널 간 필터를 적용한다.
이를 통해 더욱 효과적인 모델을 구성할 수 있게 되었다.

- Entry Flow와 Exit Flow
Xception은 "Entry Flow"와 "Exit Flow"라 불리는 두 부분으로 구성된다.
Entry Flow는 초기의 특성을 추출하고, Exit Flow는 추출된 특성을 바탕으로 최종 예측을 수행한다.

- Batch Normalization과 활성화 함수
Xception은 각 컨볼루션 층 뒤에 Batch Normalization을 적용하고, 활성화 함수로는 ReLU(Rectified Linear Unit)를 사용한다.

- Residual Connection
각 블록 사이에는 잔여 연결(residual connection)이 도입되어 그래디언트 소실 문제를 완화시켰다.

- 사전 학습 및 전이 학습
Xception은 ImageNet과 같은 대규모 데이터셋에서 사전 훈련된 모델을 활용하여 전이 학습에 유용하게 사용될 수 있다.
Xception은 깊이별 분리 컨볼루션을 활용한 효율적인 구조와 잔여 연결을 통한 향상된 그래디언트 흐름으로 인해 
기존의 모델보다 파라미터 효율성과 학습 성능에서 우수한 결과를 보이는 모델 중 하나이다.

15. SENet(Squeeze-and-Excitation Network) 
SENet(Squeeze-and-Excitation Network)은 2017년에 Jie Hu, Li Shen, Samuel Albanie, Gang Sun 등에 의해 개발된 딥러닝 모델이다. 
SENet은 주로 이미지 분류 작업에서 성능을 향상시키기 위해 설계되었으며, 모델 내부에서 채널 간 상호 의존성을 강조하는 특별한 구조를 가지고 있다.

주요 특징 및 아키텍처
- SE Block (Squeeze-and-Excitation Block)
SENet의 핵심은 Squeeze-and-Excitation Block이다. 
이 블록은 각 채널 간의 상호 의존성을 고려하여 각 채널의 중요도를 동적으로 조절한다.
먼저, Global Average Pooling을 통해 각 채널의 평균값을 계산한다. 
이렇게 얻은 평균값을 이용하여 각 채널의 중요도를 계산하는데, 이는 채널 간의 상대적인 중요성을 파악한다.
그 후, 이 중요도를 이용하여 각 채널에 가중치를 적용하여 새로운 특성을 생성한다. 
이로써 더욱 중요한 정보를 강조하고 덜 중요한 정보를 억제할 수 있다.

- Residual Connection
SENet은 Residual Network (ResNet)의 개념을 따르고 있다.
 각 블록 사이에는 잔여 연결(residual connection)이 존재하여 그래디언트 소실 문제를 완화한다.
 
- 활성화 함수 및 정규화
SENet은 주로 ReLU(Rectified Linear Unit) 활성화 함수를 사용하며, 
각 층 뒤에 Batch Normalization이나 Layer Normalization을 적용하여 안정적인 학습을 도모한다.

- 사전 학습 및 전이 학습
SENet은 대규모 데이터셋에서 미리 훈련된 모델을 활용하여 전이 학습에도 효과적으로 사용될 수 있다.

SENet은 주로 이미지 분류 태스크에서 다양한 딥러닝 모델과 함께 사용되어 성능을 향상시키는 데 기여했다. 
특히, 채널 간의 상호 의존성을 고려한 SE Block은 모델이 학습하는 특성의 품질을 높이고, 
특히 중요한 정보에 더 집중할 수 있게 해주는 중요한 아이디어 중 하나로 평가된다.

16. MobileNet 
MobileNet은 2017년에 Google에서 개발된 경량 딥러닝 아키텍처로, 
주로 모바일 기기 및 임베디드 시스템에서의 실시간 이미지 분류 및 객체 감지를 위해 고안되었다. 
MobileNet은 효율적인 모델 구조로서, 모바일 기기에서도 경량하면서도 높은 성능을 제공하는 것이 목표이다.

주요 특징 및 아키텍처
- Depthwise Separable Convolution
MobileNet은 기존의 컨볼루션 연산을 Depthwise Separable Convolution으로 대체하여 경량화를 이루었다.
Depthwise Convolution은 각 입력 채널에 대해 따로따로 공간 필터를 적용하고,
Pointwise Convolution(1x1 컨볼루션)을 통해 각 채널 간의 조합을 수행한다.
이로써 일반적인 컨볼루션 연산보다 파라미터 수와 연산량을 효과적으로 줄일 수 있다.

- Width Multiplier와 Resolution Multiplier
MobileNet은 모델의 가로 방향 크기를 조절하는 Width Multiplier와 
입력 이미지의 해상도를 조절하는 Resolution Multiplier를 도입하여 모델의 크기를 조절할 수 있다.
이를 통해 모델을 더 작고 가벼운 버전으로 변형하여 필요에 따라 메모리나 계산 리소스를 적게 사용하도록 할 수 있다.

- Bottleneck 구조
MobileNet에서는 Bottleneck 구조를 사용하여 효율적인 특성 추출을 수행한다. 
각 레이어에서는 1x1 Convolution을 통해 차원을 줄이고, 
Depthwise Separable Convolution을 적용하여 경량하게 유지힌다.

- Global Average Pooling
Global Average Pooling을 사용하여 Fully Connected Layer를 대체하여 파라미터 수를 크게 줄이고, 
모델을 더욱 경량하게 만든다.

- Batch Normalization 및 ReLU 활성화 함수
각 레이어에는 Batch Normalization이 적용되고, 활성화 함수로는 ReLU(Rectified Linear Unit)가 사용된다.

MobileNet은 경량화 모델로서 모바일 기기에서의 배포에 특화되어 있다. 
그러나 경량화를 통해 모델 크기를 줄였다는 것은 일부 성능 저하를 감수해야 한다는 것을 의미하기도 한다. 
MobileNet은 모델 크기와 성능 사이의 트레이드오프를 고려하여 적절한 컨텍스트에서 활용된다.

17. 경량 알고리즘
경량 알고리즘(Lightweight Algorithm)은 주로 제한된 자원이나 환경에서 효율적으로 동작하는 알고리즘을 의미한다. 
이러한 알고리즘은 주로 모바일 기기, 임베디드 시스템, 센서 네트워크 등의 제약이 있는 환경에서 사용된다.

18. AutoML 
AutoML은 기계 학습 모델을 자동으로 선택, 훈련, 평가 및 최적화하는 기술을 가리키는 용어이다.
AutoML은 기계 학습 모델을 개발하는 일련의 과정을 자동화함으로써, 비전문가들이나 기계 학습 전문가들에게도 더 쉽게 이용할 수 있도록 한다.











